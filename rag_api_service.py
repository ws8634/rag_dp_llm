# ==============================================
# RAGæ£€ç´¢æœåŠ¡APIæ¥å£
# æä¾›RESTfulæ¥å£ï¼Œä¾›å…¶ä»–æœåŠ¡è°ƒç”¨RAGæ£€ç´¢åŠŸèƒ½
# ==============================================
import uvicorn
from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from typing import Optional
import time
import json
import threading

from enterprise_rag_with_dp_opensearch import SystemConfig, load_and_split_docs, build_vector_db, LLMWrapper, RedisCache, RAGService

# å…¨å±€å˜é‡
app = FastAPI(
    title="çŸ³åŒ–ç”Ÿäº§è¿ç»´RAGæ£€ç´¢æœåŠ¡API",
    description="ä¼ä¸šçº§çŸ³åŒ–ç”Ÿäº§è¿ç»´çŸ¥è¯†åº“æ£€ç´¢æœåŠ¡ï¼Œæ”¯æŒå›½äº§åŒ–æŠ€æœ¯æ ˆ",
    version="1.0.0"
)
rag_service = None
vector_db = None
llm = None
redis_cache = None

# è¯·æ±‚æ¨¡å‹
class RAGQueryRequest(BaseModel):
    query: str
    username: str = "anonymous"
    workshop: Optional[str] = None

# å“åº”æ¨¡å‹
class RAGQueryResponse(BaseModel):
    query: str
    response: str
    username: str
    workshop: Optional[str]
    time_taken: float
    timestamp: str
    status: str

# æœåŠ¡å¥åº·æ£€æŸ¥
class HealthCheckResponse(BaseModel):
    status: str
    timestamp: str
    services: dict

# åˆå§‹åŒ–æœåŠ¡
@app.on_event("startup")
async def startup_event():
    global rag_service, vector_db, llm, redis_cache
    print("ğŸš€ å¯åŠ¨RAGæœåŠ¡API...")
    
    # åŠ è½½æ–‡æ¡£
    split_docs = load_and_split_docs(SystemConfig.DOC_PATH)
    
    # æ„å»ºå‘é‡åº“
    vector_db = build_vector_db(split_docs)
    
    # åˆå§‹åŒ–å¤§æ¨¡å‹
    llm = LLMWrapper()
    
    # åˆå§‹åŒ–Redisç¼“å­˜
    redis_cache = RedisCache() if SystemConfig.USE_REDIS_CACHE else None
    
    # åˆå§‹åŒ–RAGæœåŠ¡
    rag_service = RAGService(vector_db, llm, redis_cache)
    
    print("âœ… RAGæœåŠ¡APIå¯åŠ¨å®Œæˆ")

# å¥åº·æ£€æŸ¥æ¥å£
@app.get("/health", response_model=HealthCheckResponse)
async def health_check():
    from enterprise_rag_with_dp_opensearch import FaultTolerance
    fault_tolerance = FaultTolerance()
    
    services_status = {
        "vector_store": fault_tolerance.check_service_health("vector_store"),
        "llm": fault_tolerance.check_service_health("llm"),
        "redis": redis_cache.client is not None if redis_cache else False
    }
    
    return HealthCheckResponse(
        status="healthy" if all(services_status.values()) else "degraded",
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
        services=services_status
    )

# RAGæ£€ç´¢æ¥å£
@app.post("/api/rag/query", response_model=RAGQueryResponse)
async def rag_query(request: RAGQueryRequest):
    if not rag_service:
        raise HTTPException(status_code=503, detail="RAGæœåŠ¡æœªåˆå§‹åŒ–")
    
    start_time = time.time()
    
    try:
        # å¤„ç†æŸ¥è¯¢
        response = rag_service.process_query(
            query=request.query,
            username=request.username,
            workshop=request.workshop
        )
        
        end_time = time.time()
        time_taken = end_time - start_time
        
        return RAGQueryResponse(
            query=request.query,
            response=response,
            username=request.username,
            workshop=request.workshop,
            time_taken=time_taken,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
            status="success"
        )
    except Exception as e:
        end_time = time.time()
        time_taken = end_time - start_time
        
        return RAGQueryResponse(
            query=request.query,
            response=f"å¤„ç†å¤±è´¥ï¼š{str(e)}",
            username=request.username,
            workshop=request.workshop,
            time_taken=time_taken,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
            status="error"
        )

# æ‰¹é‡æŸ¥è¯¢æ¥å£
class BatchQueryItem(BaseModel):
    id: str
    query: str
    username: str = "anonymous"
    workshop: Optional[str] = None

class BatchQueryRequest(BaseModel):
    queries: list[BatchQueryItem]

class BatchQueryResponse(BaseModel):
    results: list[dict]
    total: int
    timestamp: str

@app.post("/api/rag/batch_query", response_model=BatchQueryResponse)
async def batch_query(request: BatchQueryRequest):
    if not rag_service:
        raise HTTPException(status_code=503, detail="RAGæœåŠ¡æœªåˆå§‹åŒ–")
    
    results = []
    
    for item in request.queries:
        try:
            response = rag_service.process_query(
                query=item.query,
                username=item.username,
                workshop=item.workshop
            )
            results.append({
                "id": item.id,
                "query": item.query,
                "response": response,
                "status": "success"
            })
        except Exception as e:
            results.append({
                "id": item.id,
                "query": item.query,
                "response": f"å¤„ç†å¤±è´¥ï¼š{str(e)}",
                "status": "error"
            })
    
    return BatchQueryResponse(
        results=results,
        total=len(results),
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
    )

# ç³»ç»Ÿé…ç½®æ¥å£
@app.get("/api/config")
async def get_config():
    return {
        "run_mode": SystemConfig.RUN_MODE,
        "use_domestic_stack": SystemConfig.USE_DOMESTIC_STACK,
        "use_redis_cache": SystemConfig.USE_REDIS_CACHE,
        "use_multiprocess": SystemConfig.USE_MULTIPROCESS,
        "process_count": SystemConfig.PROCESS_COUNT,
        "embedding_model": SystemConfig.EMBED_MODEL_NAME,
        "similarity_threshold": SystemConfig.SIMILARITY_THRESHOLD,
        "dp_epsilon": SystemConfig.DP_EPSILON
    }

# å¯åŠ¨æœåŠ¡
if __name__ == "__main__":
    # ä¿®æ”¹é…ç½®ä¸ºæœåŠ¡å™¨æ¨¡å¼
    SystemConfig.RUN_MODE = "server"
    SystemConfig.USE_REDIS_CACHE = True
    
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        "rag_api_service:app",
        host="0.0.0.0",
        port=8000,
        reload=True if SystemConfig.RUN_MODE == "development" else False
    )